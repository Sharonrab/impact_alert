
  	
@article{1748-3190-9-2-025002,
  author={Floris van Breugel and Kristi Morgansen and Michael H Dickinson},
  title={Monocular distance estimation from optic flow during active landing maneuvers},
  journal={Bioinspiration & Biomimetics},
  volume={9},
  number={2},
  pages={025002},
  url={http://stacks.iop.org/1748-3190/9/i=2/a=025002},
  year={2014},
  abstract={Vision is arguably the most widely used sensor for position and velocity estimation in animals, and it is increasingly used in robotic systems as well. Many animals use stereopsis and object recognition in order to make a true estimate of distance. For a tiny insect such as a fruit fly or honeybee, however, these methods fall short. Instead, an insect must rely on calculations of optic flow, which can provide a measure of the ratio of velocity to distance, but not either parameter independently. Nevertheless, flies and other insects are adept at landing on a variety of substrates, a behavior that inherently requires some form of distance estimation in order to trigger distance-appropriate motor actions such as deceleration or leg extension. Previous studies have shown that these behaviors are indeed under visual control, raising the question: how does an insect estimate distance solely using optic flow? In this paper we use a nonlinear control theoretic approach to propose a solution for this problem. Our algorithm takes advantage of visually controlled landing trajectories that have been observed in flies and honeybees. Finally, we implement our algorithm, which we term dynamic peering , using a camera mounted to a linear stage to demonstrate its real-world feasibility.}
}
	